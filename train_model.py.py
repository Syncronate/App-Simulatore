import pandas as pd
from io import StringIO
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

# ============================================
# 1. STRINGA CSV CON I DATI GIA' INSERITI
# ============================================
data_csv = """Giorno;Cumulata 1295 [mm];Cumulata 2673 [mm];Cumulata 2858 [mm];Cumulata 2964 [mm];Cumulata totale;Cumulata 2 giorni precedenti;Cumulata Media;Livello idrometrico alle ore 12 [cm]
02/10/2024;44;29.4;35.2;32.8;141.4;0;35.35;121
03/10/2024;11;7.8;8.6;9.2;36.6;141.4;9.15;124
04/10/2024;22.4;5;15.6;17.2;60.2;178;15.05;125
05/10/2024;0;0;0;0;0;96.8;0;112
06/10/2024;0;0.2;0;0;0.2;60.2;0.05;102
07/10/2024;0;0;0;0;0;0.2;0;98
08/10/2024;18.4;15.6;13.4;14;61.4;0.2;15.35;121
09/10/2024;0.4;0;0.2;0.2;0.8;61.4;0.2;106
10/10/2024;2.6;14.4;17.4;11;45.4;62.2;11.35;126
11/10/2024;0;1;1;4;6;46.2;1.5;110
12/10/2024;0;0;0;0;0;51.4;0;102
13/10/2024;0;0.2;0;0;0.2;6;0.05;99
14/10/2024;0;0.2;0;0;0.2;0.2;0.05;97
15/10/2024;0;0;0;0;0;0.4;0;97
16/10/2024;1.4;2;1.8;2.2;7.4;0.2;1.85;97
17/10/2024;0;2.4;1.6;0.4;4.4;7.4;1.1;96
18/10/2024;9.2;80.2;19.4;53.2;162;11.8;40.5;239
19/10/2024;51.2;9.6;15.6;12.6;89;166.4;22.25;173
20/10/2024;1.4;0.2;0;0;1.6;251;0.4;134
21/10/2024;0.4;0;0;0.2;0.6;90.6;0.15;123
22/10/2024;2.8;1;0.8;1;5.6;2.2;1.4;116
23/10/2024;28.8;23.2;25.4;24.4;101.8;6.2;25.45;207
24/10/2024;1.8;2.6;3.8;4.4;12.6;107.4;3.15;151
25/10/2024;0;0.2;0;0.2;0.4;114.4;0.1;132
26/10/2024;0;0;0.2;0;0.2;13;0.05;124
27/10/2024;0;0.2;0;0.2;0.4;0.6;0.1;119
28/10/2024;0.2;0.2;0.2;0;0.6;0.6;0.15;116
29/10/2024;0.2;0.2;0;0.2;0.6;1;0.15;111
30/10/2024;0;0.2;0;0;0.2;1.2;0.05;111
31/10/2024;0.2;0.4;0.2;0;0.8;0.8;0.2;110
01/11/2024;0;0.4;0;0;0.4;1;0.1;108
02/11/2024;0;0.2;0;0.2;0.4;1.2;0.1;106
03/11/2024;0.4;0.4;0.2;0.2;1.2;0.8;0.3;106
04/11/2024;0.2;0.2;0;0.2;0.6;1.6;0.15;106
05/11/2024;0.2;0;0;0;0.2;1.8;0.05;105
06/11/2024;0;0;0;0;0;0.8;0;104
07/11/2024;0.2;0;0;0;0.2;0.2;0.05;103
08/11/2024;0.2;0;0;0;0.2;0.2;0.05;103
09/11/2024;0;0;0;0;0;0.4;0;103
10/11/2024;0.2;0;0;0;0.2;0.2;0.05;101
11/11/2024;0;0.2;0.8;0;1;0.2;0.25;101
12/11/2024;0.2;0.2;0.4;0;0.8;1.2;0.2;102
13/11/2024;11.8;9.8;11;9.8;42.4;1.8;10.6;105
14/11/2024;4;2.6;3;2.2;11.8;43.2;2.95;107
15/11/2024;0;0;0;0;0;54.2;0;103
16/11/2024;0;0.2;0;0;0.2;11.8;0.05;102
17/11/2024;0;0;0;0;0;0.2;0;101
18/11/2024;0.2;0;0;0;0.2;0.2;0.05;100
19/11/2024;0;0.2;0.2;0;0.4;0.2;0.1;100
20/11/2024;0;10.2;0.6;5.8;16.6;0.6;4.15;104
21/11/2024;3;1.6;1.8;1.4;7.8;17;1.95;101
22/11/2024;0;0.8;0;0;0.8;24.4;0.2;100
23/11/2024;0;0;0;0;0;8.6;0;99
24/11/2024;0;0;0;0;0;0.8;0;99
25/11/2024;0;0.2;0;0;0.2;0;0.05;99
26/11/2024;0;0;0;0;0;0.2;0;99
27/11/2024;0;3.6;2.6;4.4;10.6;0.2;2.65;100
28/11/2024;2.6;0;0.2;0.2;3;10.6;0.75;100
29/11/2024;3.4;0.8;2;0;6.2;13.6;1.55;97
30/11/2024;0;0;0;0;0;9.2;0;98
01/12/2024;0;0;0;0;0;6.2;0;98
02/12/2024;0;0;0;0;0;0;0;97
03/12/2024;3;4.2;2.4;6.4;16;0;4;99
04/12/2024;21.2;14.4;18.8;21.8;76.2;16;19.05;126
05/12/2024;0;0;0;0;0;92.2;0;114
06/12/2024;0;0.2;0;0;0.2;76.2;0.05;108
07/12/2024;9.8;12.2;10.6;11.4;44;0.2;11;132
08/12/2024;1;2.6;2.4;2.2;8.2;44.2;2.05;128
09/12/2024;0.2;0;0;0;0.2;52.2;0.05;116
10/12/2024;1.4;6.4;3.2;3.6;14.6;8.4;3.65;114
11/12/2024;0.4;0.8;0;0.2;1.4;14.8;0.35;111
12/12/2024;0.2;0;0;0;0.2;16;0.05;109
13/12/2024;7.8;9;9.8;12.2;38.8;1.6;9.7;134
14/12/2024;0.8;0.2;1;0.2;2.2;39;0.55;122
15/12/2024;0;0.4;0;0;0.4;41;0.1;115
16/12/2024;0;0.2;0;0;0.2;2.6;0.05;111
17/12/2024;0;0.2;0;0;0.2;0.6;0.05;109
18/12/2024;0;0;0;0;0;0.4;0;108
19/12/2024;8;18.6;12.8;26.2;65.6;0.2;16.4;152
20/12/2024;27.8;5.2;30;12.4;75.4;65.6;18.85;163
21/12/2024;0.2;0;0;0;0.2;141;0.05;138
22/12/2024;28.4;36;46;42.6;153;75.6;38.25;333
23/12/2024;1.8;5.4;2.6;2.4;12.2;153.2;3.05;162
24/12/2024;0;0;0;0;0;165.2;0;145
25/12/2024;0;0;0;0;0;12.2;0;138
26/12/2024;0;0;0;0;0;0;0;135
27/12/2024;0;0;0;0;0;0;0;133
28/12/2024;0;0;0;0;0;0;0;131
29/12/2024;0;0;0;0;0;0;0;130
"""

# ============================================
# 2. CREAZIONE DEL DATAFRAME
# ============================================
df = pd.read_csv(
    StringIO(data_csv),
    sep=';',             # separatore di colonna
    decimal='.',         # separatore decimale
    parse_dates=['Giorno'],
    dayfirst=True        # formato data gg/mm/aaaa
)

# ============================================
# 3. PREPARAZIONE DI FEATURE E TARGET
# ============================================
# Rimuoviamo la colonna Giorno (o la usiamo per feature engineering se serve).
X = df.drop(columns=['Giorno', 'Livello idrometrico alle ore 12 [cm]'])
y = df['Livello idrometrico alle ore 12 [cm]']

# ============================================
# 4. TRAIN/TEST SPLIT
# ============================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42
)

# ============================================
# 5. TRAINING DEL MODELLO
# ============================================
model = RandomForestRegressor(
    n_estimators=100,
    random_state=42
)
model.fit(X_train, y_train)

# ============================================
# 6. VALUTAZIONE DEL MODELLO
# ============================================
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error (MAE):", mae)
print("R^2 Score:", r2)

# ============================================
# 7. ESEMPIO DI PREDIZIONE
# ============================================
# Se in futuro vuoi fare previsioni su nuovi dati (stessa struttura di X), potrai fare:
# new_data = pd.DataFrame({
#    "Cumulata 1295 [mm]": [ ... ],
#    "Cumulata 2673 [mm]": [ ... ],
#    "Cumulata 2858 [mm]": [ ... ],
#    "Cumulata 2964 [mm]": [ ... ],
#    "Cumulata totale": [ ... ],
#    "Cumulata 2 giorni precedenti": [ ... ],
#    "Cumulata Media": [ ... ],
# })
# prediction = model.predict(new_data)
# print("Livello idrometrico previsto:", prediction)
